<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Wikipedia Summary - Angelina Li's CS Wellesley Site">
  <meta name="author" content="Angelina Li">
  <title>Digital Natives Summary - Angelina Li</title>

  <link rel="icon" href="../../img/favicon/favicon-16.png" type="image/png" sizes="16x16">
  <link rel="icon" href="../../img/favicon/favicon-32.png" type="image/png" sizes="32x32">
  <link rel="icon" href="../../img/favicon/favicon-96.png" type="image/png" sizes="96x96">

  <!-- Bootstrap core CSS -->
  <link href="../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <!-- Custom fonts for this template -->
  <link href="../../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|PT+Sans" rel="stylesheet">
  <!-- Plugin CSS -->
  <link href="../../vendor/magnific-popup/magnific-popup.css" rel="stylesheet">
  <!-- Custom styles for this template -->
  <link href="../../old_style.css" rel="stylesheet">
</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">Digital Natives - Summary</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="../../">
              <i class="fa fa-home"></i> Home
            </a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="../">CS234</a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="blog.html">Blog</a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#abstract">Abstract</a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#introduction">Intro</a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#methodology">Method</a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#results&analysis">Results & Analysis</a>
          </li>

          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#conclusion">Conclusion</a>
          </li>

        </ul>
      </div>

    </div>
  </nav>

  <!-- Introduction to page -->
  <header class="masthead">
    <div class="header-content">
      <div class="header-content-inner">
        <h1 id="homeHeading"><span>Digital Natives - Summary</span></h1>
      </div>
    </div>
  </header>

  <section class="bg-dark" id="abstract">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto text-white">
          <!-- <div class="text-center"><i class="fa fa-4x fa-book sr-iconas"></i></div> -->
          <h2 class="display-4 text-center">Abstract</h2>
          <hr class="light">

          <p class="lead">This project is a machine-learning driven exploration of online speech patterns. Here is the <a href="blog.html">project blog</a>.</p>

          <p>How do I, and others, communicate online on different media platforms? In this research investigation, I thoroughly investigate my communication through Facebook Messenger and GMail. I uncover several phenomena regarding my use of language online:</p>

          <ol>
            <li>I don't seem to use significantly different language on Facebook Messenger as compared to my friends, and the distinguishing characteristics of my Facebook messages seem to rely more on the relative frequencies with which I use everyday words as compared to others.</li>
            <li>A very significant portion of my Facebook conversations occur between me and only a handful of friends. 17% of the Facebook messages that I send and receive and between me and one other person.</li>
            <li>I seem to codeshift when talking to different friends online. Again, the characteristics that distinguish my 'voice' from one thread to another are subtle and depend on the relative frequencies with which I use common words.</li>
            <li>The words I use in email messages appear more formal than the words I use in Facebook messages - often I will include my full name.</li>
            <li>The messages I send through GMail are significantly longer than the messages I send through Facebook.</li>
          </ol>

        </div>
      </div>
    </div>
  </section>

  <section id="introduction">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <!-- <div class="text-center"><i class="fa fa-4x fa-address-book sr-iconas"></i></div> -->
          <h2 class="display-4 text-center">Introduction</h2>
          <hr class="dark">

          <p>How do we talk to each other online, as digital natives? How do we communicate differently across different media platforms, and to different people? Unfortunately, there is very little academic literature published on the ways in which we communicate online. While there is <a href="https://www.researchgate.net/profile/Bei_Yu2/publication/236246670_Classifying_Business_Marketing_Messages_on_Facebook/links/56bcb34408ae6cc737c6335b.pdf">some</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1001.5025&rep=rep1&type=pdf">research</a> discussing the use of Facebook Messenger to further business motivations, very few people have seriously investigated how we communicate in our personal lives on Facebook and other media platforms.</p>

          <p>This dearth of research is especially troubling given that <a href="http://universe.byu.edu/2013/07/07/1communication-changes-with-technology-social-media/">more and more of our communication is starting to occur on online platforms</a>. It is both personally and intellectually important to me to more thoroughly understand how I manage my relationships with friends through different social media platforms.</p>

          <p>In this project, I am attempting to explore several questions about my online communication patterns, as well as about the speech patterns of other people. I'll be asking five core questions:</p>
          
          <ol>
            <li>What words do I use that differentiate myself the greatest from my friends over Facebook Messenger?</li>
            <li>Which people do I talk to on Facebook Messenger - and how frequently do I talk to each of them? Do I talk to some significantly more than others?</li>
            <li>Do I use different words to talk to different people on Facebook?</li>
            <li>How do I express myself differently via e-mail as opposed to via Facebook Messenger?</li>
            <li>Do the emails I send contain more words on average than the messages I send on Facebook?</li>
          </ol>

          <p>To answer these questions, I'll be using two primary source of data:</p>
          
          <ul>
            <li>Facebook messenger data</li>
            <li>GMail email data</li>
          </ul>

          <p>I'll also use a list of the top 500 words in the English Language, as compiled by <a href="https://books.google.com/ngrams/info">Google's Trillion Word Corpus</a>. I pulled these words from a <a href="https://github.com/first20hours/google-10000-english">repository</a> created by <a href="https://github.com/first20hours">Josh Kaufman</a>.</p>

        </div>
      </div>
    </div>
  </section>

  <section class="bg-dark" id="methodology">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto text-center text-white">
          <!-- <div class="text-center"><i class="fa fa-4x fa-pencil-square-o sr-iconas"></i></div> -->

          <h2 class="display-4 text-center">Methodology</h2>
          <hr class="light">

          <p>The bulk of this project will comprise of creating Multinomial Naive Bayes classifiers, in order to classify text as belonging to different categories. There are two core assumptions we make when using a Naive Bayes classifier: First, that the order of words in a corpus of text doesn't matter (the 'bag of words' assumption), and second, that the words that appear in any given fragment of text are independent from each other.</p>

          <p>As <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.2085&rep=rep1&type=pdf">other academics have discussed</a>, it is likely that neither assumption will be entirely upheld in any investigative setting. In particular, the assumption that the probability of one word appearing in a document is independent from the probability of any other word appearing in a document seems clearly false - since bodies of text often focus on specific topics (which often involve repeating words relevant to those words), when one word occurs in any body of text it is more likely to appear again in the same body of text. Nevertheless, the Naive Bayes classifier seems to classify text relatively well despite these limitations, and thus will be the model I shall use throughout this analysis.</p>

          <p>In the following section, I describe my strategy in tackling each of the following challenges.</p>

          <h4> Data Cleaning</h4>
          
          <h5>Facebook data</h5>

          <p>Facebook gave me my Messenger data in the form of a series of .html files containing my messages. Each file contained information on a specific Facebook thread. After parsing through each file, I was left with a dataset containing all the messages I'd either sent or received over my time on Facebook. At the end of this process, because my overall dataset was too large to work with directly (containing 532,108 messages entries), I randomly sampled 10,000 messages from this dataset to create a more manageable subset of data for preliminary exploration purposes.</p>

          <h5>GMail data</h5>

          <p>To save time while downloading my GMail data, I only downloaded the emails recorded as belonging in my Sent folder, since for this portion of the project I was only concerned with emails I had personally written.</p>

          <p>From the data I was provided, I was able to create a dataset containing the text all the messages I've written on my wellesley.edu GMail account, as well as the subject title and intended recipient of each entry. Because some messages initially contained the text of several emails (for instance, some messages contained the text of a forwarded email), to maintain the sanctity of my dataset I retained only the first email in any email chain I detected.</p>

          <p>I ran into some problems while parsing my data, such that I was ultimately unable to parse some messages. Eventually, I decided to drop any messages that I couldn't directly clean, since it didn't particularly matter for this project to have a full set of all GMail messages I've ever sent. This left me with 1896 well formatted GMail messages to use.</p>

          <h4>Facebook: Me vs. My Friends</h4>

          <h5>What words do I use that differentiate myself the greatest from my friends over Facebook Messenger?</h5>

          <p>After parsing all my Facebook messenger data, I was able to examine the differences in the words my friends and I use on Facebook Messenger. To do this, I first labelled all the messages in my dataset as either belonging to me, or not to me. Next, I randomly segmented my data into a training and testing set of equal lengths. Then, I vectorized my training data and trained a multinomial naive bayes classifier to predict which messages were written by me and which were not written by me. I also extracted the most predictive features from this classifier, and evaluated its overall accuracy rate.</p>

          <p>In order to expand upon my work, I also trained multinomial naive bayes classifiers on data segmented by years, and by the top 5 most active conversation threads I participated in. In order to do this, I created separate training and testing datasets (Again, randomly shuffled) for each year from 2015-2017, as well as for the top 5 conversation threads I engaged in. I listed the most predictive features and evaluated the accuracy rate of each of the classifiers trained on these data segments.</p>

          <p>Then, in an attempt to reduce noise from my dataset, I decided to strip out the top 500 English words from each message I used within my training samples. To do this, I used a list of the top 500 words in the English Language, as compiled by <a href="https://books.google.com/ngrams/info">Google's Trillion Word Corpus</a>. I pulled these words from a <a href="https://github.com/first20hours/google-10000-english">repository</a> created by <a href="https://github.com/first20hours">Josh Kaufman</a>. Then, I repeated my previous analyses on both the sample overall and on each segmented dataset I had previously analyzed. This attempt to reduce noise did not significantly improve the accuracy of my classifier, so I ultimately discarded this method.</p>

          <p>Finally, I spent some time examining the classifier I had built and testing different hypotheses for why its accuracy rate might be so low.</p>

          <p>The first hypothesis I examined was the possibility that each individual message sent on Facebook simply contains too little information to be classified accurately. In testing this assumption, first I generated random pseudo-messages of varying lengths from a corpus of words that made up my testing data. I then plotted the average accuracy of my classifier at predicting made up messages of varying lengths. Then, I looked back on the data I had access to, and plotted the length of a message against the average accuracy of my classifier in labelling messages of each length.</p>

          <p>The second hypothesis I examined was the possibility that I might be using too few data in my classifier. To address this, I repeated my initial analyses on both the sample overall and on each segmented dataset described above, but on all my Facebook messages as opposed to the random sample I had selected previously.</p>

          <h5>Which people do I talk to on Facebook Messenger - and how frequently do I talk to each of them? Do I talk to some significantly more than others?</h5>

          <p>To answer this question, I first found the top conversation threads I engage in, by the number of messages I've either sent or received within each thread. Then, I plotted the distribution of each of my Facebook threads against the percentage of my overall messages that each thread contained. I created these plots both on the sample and population level.</p>

          <h5>Do I use different words to talk to different people on Facebook?</h5>

          <p>To answer this question, I created a dataset of the messages I send to the threads I most often engage in. I randomly segmented this dataset into training and testing sets of equal lengths, vectorized my training data and trained a multinomial naive bayes classifier to predict which messages were sent to which friends. As before, I noted both the accuracy of my classifier overall and the features that were most predictive for each of my top threads. I repeated this analysis for my top 10, top 5 and top 2 most frequent threads.</p>

          <p>I decided to look only at the differences in the way I talk within my most active Messenger threads in order to ensure that I would have enough data to properly train and test a classifier.</p>

          <h4>Different Platforms: Messenger vs. GMail</h4>

          <h5>How do I express myself differently via e-mail as opposed to via Facebook Messenger?</h5>

          <p>After extracting my Facebook and GMail data, I created a dataset of the contents of all my Facebook and GMail messages. I randomly segmented this dataset into training and testing sets of equal lengths, vectorized my training data and trained a multinomial naive bayes classifier on my data to predict which messages were facebook messages and which were GMail messages. As before, again I noted the accuracy of my classifier and its most predictive features.</p>

          <h5>Do the emails I send contain more words on average than the messages I send on Facebook?</h5>

          <p>To answer this question, I created two datasets of the lengths of my Facebook and GMail messages respectively. Then, I used a two-sample t-test to determine whether the distributions were statistically different from each other. Then, I generated some distribution plots of the lengths of Facebook and Gmail messages respectively.</p>

        </div>
      </div>
    </div>
  </section>

  <section id="results&analysis">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto text-center">
          <!-- <div class="text-center"><i class="fa fa-4x fa-area-chart sr-iconas"></i></div> -->
          <h2 class="display-4 text-center">Results and Analysis</h2>
          <hr class="dark">

          <h4>What words do I use that differentiate myself the greatest from my friends over Facebook Messenger?</h4>

          <p>The classifier I created ultimately had an accuracy rate of 66.44%, as run on the entire population of messages I've ever sent to or received from anyone on Facebook.</p>

          <p>The top 10 features that distinguished my Facebook messages from the facebook messages of others were: the, to, you, it, and, that, is, of, in, we.</p>

          <p>As you might notice from this list, all of these words are relatively generic. What seemed to make them good predictors of my online presence is the frequency with which I use them relative to others. Even when I stripped out the top 500 words in the English language, the top 10 distinguishing features of my Facebook messages were still relatively mundane.</p>

          <p>They were as follows: im, dont, lol, yeah, oh, ill, okay, ok, thanks, thats.</p>

          <p>It's worth noting that the accuracy of my predicted decreased after I parsed out common words - which might be a sign that my top features indicate some subtle speech patterns I would not otherwise have suspected, and which are useful for predictive purposes.</p>

          <p>It appears as though, on average, my segmented classifications did slightly better than my main classifier. This makes sense: it might be the case that my speaking style varies too drastically across years or across different conversation threads for my main classifier to pick out many distinct words that most significantly predict whether a given text message was written by me or by someone else.</p>
          
          <p>My segments by thread classifications also seem slightly more accurate than my year based segments - again, this makes sense, because by controlling for the different people I have conversations with, I at least partially control for time as well - for instance, 2 out of my top 5 threads were started only after my sophomore year of college (2016) - thus implicitly controlling for some of the changes in my speaking style across time.</p>

          <p>One general reason why my classifier might have performed poorly on this dataset is because my average Facebook message might not have been long enough for my classifier to make meaningful predictions here. To test this hypothesis, I generated messages of varying lengths and plotted the average accuracy of my classifier at classifying messages of those lengths.</p>

          <h6>Plot of generated message lengths against classifier accuracy<br>
          <img src="img/len_accuracy_generated.png" width="60%"></h6>

          <p>I also plotted actual message lengths in my dataset against average classifier accuracy.</p>

          <h6>Plot of message lengths against classifier accuracy<br>
          <img src="img/len_accuracy_actual.png" width="60%"></h6>

          <p>These plots seem to demonstrate the notion that our classifier performs better at classifying longer messages, although there is enough variance here that that we perhaps can't be entirely certain of this effect.</p>

          <h4>Which people do I talk to on Facebook Messenger - and how frequently do I talk to each of them? Do I talk to some significantly more than others?</h5>

          <p>From my data exploration, it seems like I talk to some people on Facebook Messenger much more than I do to other people.</p>

          <h6>Distribution of all Facebook threads against the percentage of all messages contained in each thread<br>
          <img src="img/friends_perc_all.png" width="60%"></h6>

          <h6>Distribution of top 50 Facebook threads against the percentage of all messages contained in each thread<br>
          <img src="img/friends_perc_top50.png" width="60%"></h6>

          <p>Since it appeared as though I just have one highly anomalous thread - who takes up around 17% of my overall messages sent or received - I also plotted the distribution of Facebook threads after dropping this data point.</p>

          <h6>Distribution of all Facebook threads except the top thread, against the percentage of all messages contained in each thread<br>
          <img src="img/friends_perc_without1.png" width="60%"></h6>

          <p>As shown clearly in these plots, it seems as though I talk to some individuals on Facebook significantly more than I talk to some others, to the degree that the frequency distribution of my Facebook threads looks highly exponential.</p>

          <h4>Do I use different words to talk to different people on Facebook?</h5>

          <p>The classifier I trained to predict who the messages I sent were directed at was surprisingly accurate relative to my baseline predictions - it was 84.465% accurate at labelling messages sent between my top two threads, 69.239% accurate at labelling messages sent between my top five threads and 55.915% accurate at labelling messages sent between my top ten threads. In each case, the classifier significantly outcompeted random chance.</p>

          <p>It was interesting that here again, the features that most distinguished different threads from each other were relatively mundane - for instance, the top 10 words distinguishing between my top two threads were, in order: is, so, that, it, lol, of, and, you the, to.</p>

          <p>It seems like again, these features are more important due to their relative frequencies of use between different threads of conversations.</p>

          <h4>How do I express myself differently via e-mail as opposed to via Facebook Messenger?</h5>

          <p>The classifier I trained to predict whether messages were GMail or Facebook messages was much more successful than any of my Facebook classifiers, correctly labelling new messages 94% of the time. I suspect this is because there is a more significant difference between the kinds of words that people tend to use on GMail (which seem to be more formal) and the words people use over Messenger (which are almost always less formal).</p>

          <p>I extracted the features that best predicted whether or not a message should be classified as a GMail message and plotted some of these features in a wordcloud:</p>

          <h6>WordCloud Representation of Top Features<br>
          <img src="img/gmail_fb_top_features.png" width="60%"></h6>

          <h4>Do the emails I send contain more words on average than the messages I send on Facebook?</h5>

          <p>The answer to this question is a resounding yes. In the samples over which I tested message length, the average length of a GMail message was 59 words long, whereas the average length of a Facebook message was 7 words long. The two-sample hypothesis test I conducted concluded there is only a 2.841 Ã— 10-168% likelihood that these two samples in fact came from the same distribution.</p>

          <h6>Distribution of Facebook message lengths<br>
          <img src="img/fb_dist.png" width="60%"></h6>

          <h6>Distribution of GMail message lengths<br>
          <img src="img/gmail_dist.png" width="60%"></h6>

          <h6>Comparison of Facebook and GMail message lengths<br>
          <img src="img/fb_gmail_dist.png" width="60%"></h6>

        </div>
      </div>
    </div>
  </section>

  <section class="bg-dark" id="conclusion">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto text-white text-center">
          <!-- <div class="text-center"><i class="fa fa-4x fa-newspaper-o sr-iconas"></i></div> -->

          <h2 class="display-4 text-center">Conclusion</h2>
          <hr class="light">

          <p>One of my basic takeaways from this project was that the Multinomial Naive Bayes Classifier performs relatively poorly in the context of Facebook Messenger based text based analysis. Even after all of the ways I attempted to troubleshoot my model, the highest accuracy I achieved in classifying my messages based on whether or not I sent them was only 66.444% - still barely better than average. This exposes some of the real limitations of Naive Bayes Classifiers - perhaps one conclusion might be that a more sophisticated model than a "Bag of Words" construct might be needed to investigate the subtler differences in the ways we communicate online.</p>

          <p>Nevertheless, I learned several interesting things about my habits online: It was interesting to see that the distribution of threads I spend time talking to on Facebook is so skewed - I hadn't been fully aware of this before, and this realization makes me wonder whether I should start investing more time online talking to a greater variety of people.</p>

          <p>Furthermore, it was surprising to me that, for all the classifiers I created, the words that distinguished my online communication behaviors were relatively mundane. It seems like unconsciously, I might be using some words in slightly different ways from how other people (or myself in different contexts) use them. These subtleties of language are not ones I had previously noticed, and this project has made me more curious to spot these distinctions in real life.</p>

          <p>Finally, it was interesting to note that my writing style between GMail and Facebook messages varies so prominently, both in terms of the words I use as well as in terms of the length of my writing. This was something I suspected prior to this project, but wasn't something I actively noticed until now.</p>

        </div>
      </div>
    </div>
  </section>

  <!-- Bootstrap core JavaScript -->
  <script src="../../vendor/jquery/jquery.min.js"></script>
  <script src="../../vendor/popper/popper.min.js"></script>
  <script src="../../vendor/bootstrap/js/bootstrap.min.js"></script>
  <!-- Plugin JavaScript -->
  <script src="../../vendor/jquery-easing/jquery.easing.min.js"></script>
  <script src="../../vendor/scrollreveal/scrollreveal.min.js"></script>
  <script src="../../vendor/magnific-popup/jquery.magnific-popup.min.js"></script>
  <!-- Custom scripts for this template -->
  <script src="../../style/js/creative.min.js"></script>
</body>

</html>
